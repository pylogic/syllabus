## lesson 1 machine learning basic concepts
* what is machine learning?
* what is superised learning n unsupervised learning?
* what is the same and different concept between regression and classification
* give examples of clustering task


## lesson 2 one variable linear regression
* what is the training set?
* what is the algorithm for linear regression with one variable?
* what is the input, output and parameters of the algorithm?
* what is the hypothesis function h_theta?
* what is the cost function J and how to evaluate?
* what is the start point for hypothesis func and cost func?
* what is the J surface to depict the gradient descent?
* how the parameters are updated step by step?
* what does the convergence means?
* describe learning rate and cost func derivative on parameters
* what is a overshoot?
* what will happen if the parameters goes to a local optima and global optima?
* why a decent fixed learning rate can converge to a minimum (local or global)
* what is a convex and bowl shaped function?
* what is called with "batch" gradient descent?

## lesson 3